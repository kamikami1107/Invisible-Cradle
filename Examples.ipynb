{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python372jvsc74a57bd0318f76b295c7a822fb965747121f10847a6aa01c560436e9046f5eb1a3720bf6",
   "display_name": "Python 3.7.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Computing saliency masks with the PAIRML saliency library (for TF2 and other frameworks)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- [XRAI paper](https://arxiv.org/abs/1906.02825)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This notebook assumes you have the saliency pip package installed. To install run (use pip3 for python 3.x):\n",
    "\n",
    "pip install saliency"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install saliency[tf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib import pylab as P\n",
    "\n",
    "# From our repository.\n",
    "import saliency.core as saliency\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "### Utility methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "\n",
    "  P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im, cmap='inferno')\n",
    "  P.title(title)\n",
    "\n",
    "def ShowDivergingImage(grad, title='', percentile=99, ax=None):  \n",
    "  if ax is None:\n",
    "    fig, ax = P.subplots()\n",
    "  else:\n",
    "    fig = ax.figure\n",
    "  \n",
    "  P.axis('off')\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "  im = ax.imshow(grad, cmap=P.cm.coolwarm, vmin=-1, vmax=1)\n",
    "  fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "  P.title(title)\n",
    "\n",
    "def LoadImage(file_path):\n",
    "  im = PIL.Image.open(file_path)\n",
    "  im = im.resize((224,224))\n",
    "  im = np.asarray(im)\n",
    "  return im\n",
    "\n",
    "def PreprocessImage(im):\n",
    "  im = tf.keras.applications.vgg16.preprocess_input(im)\n",
    "  return im"
   ]
  },
  {
   "source": [
    "### Loading the VGG16 model for ImageNet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "conv_layer = m.get_layer('block5_conv3')\n",
    "model = tf.keras.models.Model([m.inputs], [conv_layer.output, m.output])"
   ]
  },
  {
   "source": [
    "call_model_function is how we pass inputs to our model and receive outputs necessary to computer saliency masks. The description of this method and necessary outputs is in the base CoreSaliency description, as well as separately for each method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx_str = 'class_idx_str'\n",
    "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
    "    target_class_idx =  call_model_args[class_idx_str]\n",
    "    images = tf.convert_to_tensor(images)\n",
    "    with tf.GradientTape() as tape:\n",
    "        if expected_keys==[saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
    "            tape.watch(images)\n",
    "            _, output_layer = model(images)\n",
    "            output_layer = output_layer[:,target_class_idx]\n",
    "            gradients = np.array(tape.gradient(output_layer, images))\n",
    "            return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "        else:\n",
    "            conv_layer, output_layer = model(images)\n",
    "            gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
    "            return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
    "                    saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}"
   ]
  },
  {
   "source": [
    "## Load an image and infer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像のリサイズ\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#画像の読み込み\n",
    "beautiful_view = Image.open(\"good_1_3AA.jpg\")\n",
    "\n",
    "#画像を表示して確認\n",
    "#plt.imshow(beautiful_view)\n",
    "\n",
    "#画像のリサイズ\n",
    "small_beautiful_view = beautiful_view.resize((299, 299))\n",
    "\n",
    "#リサイズした画像を表示して確認\n",
    "plt.imshow(small_beautiful_view)\n",
    "\n",
    "#リサイズした画像を名前をつけて保存\n",
    "small_beautiful_view.save(\"good_1_3AA_mini.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "im_orig = LoadImage('./good_1_3AA_mini.jpg')\n",
    "#print(im_orig)\n",
    "im = PreprocessImage(im_orig)\n",
    "#print(str(im))\n",
    "\n",
    "# Show the image\n",
    "ShowImage(im_orig)\n",
    "\n",
    "i, predictions = model(np.array([im]))\n",
    "#print(i)\n",
    "#print(predictions)\n",
    "prediction_class = np.argmax(predictions)#[0]\n",
    "call_model_args = {class_idx_str: prediction_class}\n",
    "#print(prediction_class)\n",
    "#print(call_model_args)\n",
    "\n",
    "print(\"Prediction class: \" + str(prediction_class))  # Should be a doberman, class idx = 236\n"
   ]
  },
  {
   "source": [
    "## XRAI Full and Fast"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the saliency object. This alone doesn't do anthing.\n",
    "xrai_object = saliency.XRAI()\n",
    "\n",
    "# Compute XRAI attributions with default parameters\n",
    "xrai_attributions = xrai_object.GetMask(im, call_model_function, call_model_args, batch_size=20)\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 3\n",
    "UPSCALE_FACTOR = 20\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Show original image\n",
    "ShowImage(im_orig, title='Original Image', ax=P.subplot(ROWS, COLS, 1))\n",
    "\n",
    "# Show XRAI heatmap attributions\n",
    "ShowHeatMap(xrai_attributions, title='XRAI Heatmap', ax=P.subplot(ROWS, COLS, 2))\n",
    "\n",
    "# Show most salient 30% of the image\n",
    "mask = xrai_attributions > np.percentile(xrai_attributions, 70)\n",
    "im_mask = np.array(im_orig)\n",
    "im_mask[~mask] = 0\n",
    "ShowImage(im_mask, title='Top 30%', ax=P.subplot(ROWS, COLS, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XRAIParameters and set the algorithm to fast mode which will produce an approximate result.\n",
    "xrai_params = saliency.XRAIParameters()\n",
    "xrai_params.algorithm = 'fast'\n",
    "\n",
    "# Compute XRAI attributions with fast algorithm\n",
    "xrai_attributions_fast = xrai_object.GetMask(im, call_model_function, call_model_args, extra_parameters=xrai_params, batch_size=20)\n",
    "\n",
    "# Set up matplot lib figures.\n",
    "ROWS = 1\n",
    "COLS = 3\n",
    "UPSCALE_FACTOR = 20\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Show original image\n",
    "ShowImage(im_orig, title='Original Image', ax=P.subplot(ROWS, COLS, 1))\n",
    "\n",
    "# Show XRAI heatmap attributions\n",
    "ShowHeatMap(xrai_attributions_fast, title='XRAI Heatmap', ax=P.subplot(ROWS, COLS, 2))\n",
    "\n",
    "# Show most salient 30% of the image\n",
    "mask = xrai_attributions_fast > np.percentile(xrai_attributions_fast, 70)\n",
    "im_mask = np.array(im_orig)\n",
    "im_mask[~mask] = 0\n",
    "ShowImage(im_mask, 'Top 30%', ax=P.subplot(ROWS, COLS, 3))"
   ]
  }
 ]
}